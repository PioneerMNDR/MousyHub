using LLama;
using LLama.Abstractions;
using LLama.Batched;
using LLama.Common;
using LLMRP.Components.Models.Model;

namespace LLMRP.Components.Models.LLama
{
    public class LocalLlamaCore
    {
        string modelPath = "";
        LLamaWeights? weights = null;
        BatchedExecutor? executor = null;
        StatelessExecutor? Statlessexecutor = null;
        ModelParams? Params = null;

        private List<LocalLlamaContextBranch> Branches = new List<LocalLlamaContextBranch>();

        public async Task Run(ModelParams modelParams)
        {
            await Task.Run(() =>
            {
                weights = LLamaWeights.LoadFromFile(modelParams);
            });
            executor = new BatchedExecutor(weights, modelParams);
            Statlessexecutor = new StatelessExecutor(weights, modelParams);
            Params = modelParams;
        }

        public async Task<MessageResponse> Generate(string promt, InferenceParams param, CancellationToken cancellationToken)
        {

            MessageResponse messageResponse = new MessageResponse("", true, "");
            try
            {
                var stream = Statlessexecutor.InferAsync(promt, param, cancellationToken);
                await foreach (var text in stream.WithCancellation(cancellationToken))
                {
                    messageResponse.Content += text;
                }
                return messageResponse;
            }
            catch (Exception ex)
            {

                messageResponse.IsSuccess = false;
                messageResponse.ErrorMessage = ex.Message;
                return messageResponse;
            }


        }

        public async Task GenerateStream(string promt, string id, InferenceParams param, Func<MessageResponse, Task> onTokenRecieved, CancellationToken cancellationToken)
        {
         
               try
            {
                var responsetext = "";
                await foreach (var text in executor.InferAsync(editPromt, param, cancellationToken))
                {
                    await onTokenRecieved(new MessageResponse(text, true, ""));
                    responsetext += text;
                }
        
        
            }

            catch (Exception exc)
            {
                await onTokenRecieved(new MessageResponse(null, false, exc.Message));
                return;
            }

       
        }
       
        public async Task<string> ModelInfo()
        {
            return Params.ModelPath;
        }
        public async Task<bool> Status()
        {
            if (executor != null)
            {
                return true;
            }
            return false;

        }
    }
}
